{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "changing-approach",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import re\n",
    "from datetime import datetime\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urljoin\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from requests_html import HTMLSession\n",
    "import nest_asyncio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "metric-quantity",
   "metadata": {},
   "outputs": [],
   "source": [
    "frameworks = ['Frontend','Mobile','Backend','Software-Engineering/OOP','Data Science', 'Low Level',\n",
    "              'Databases','Cloud Computing','AI / ML','Testing/Utility', 'Animation']\n",
    "skill_dict = {} #Initialize our dictionary with frameworks as keys and empty lists as values\n",
    "for i in frameworks:\n",
    "    skill_dict[i] = []\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dedicated-glenn",
   "metadata": {},
   "source": [
    "## Generate a url with our input parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "spanish-sphere",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_url(position,location,date):\n",
    "    template = 'https://www.indeed.com/jobs?q={}&l={}&fromage={}'\n",
    "    url = template.format(position,location,date)\n",
    "    return url"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "linear-voltage",
   "metadata": {},
   "source": [
    "## Generate full description url from first url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "weird-airline",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_details_url(url,advn,vjk):\n",
    "    template = url + '&advn={}&vjk={}'\n",
    "    details_url = template.format(advn,vjk)\n",
    "    return details_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "acoustic-magnitude",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = get_url('software','california','7')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "individual-burst",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main (position, location):\n",
    "    job_desc = [] #list containing all descriptions\n",
    "    length = len(cards)\n",
    "    \n",
    "    while True:\n",
    "        response = requests.get(url)\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        cards = soup.find_all('div', 'jobsearch-SerpJobCard')\n",
    "        job_desc = [] #list containing all descriptions\n",
    "        length = len(cards)\n",
    "        \n",
    "        for x in range(length):\n",
    "            advn = cards[x].get('data-empn')\n",
    "            vjk = cards[x].get('data-jk')\n",
    "            details_url = get_details_url(url,advn,vjk) #append and generate new Url\n",
    "\n",
    "            #Open and load page using webdriver so we can get parse elements that load after our initial request\n",
    "\n",
    "            browser = webdriver.Chrome(r'C:\\Program Files (x86)\\Google\\Chrome\\Application\\chromedriver.exe')  \n",
    "            browser.get(details_url)\n",
    "            htmlSource = browser.page_source\n",
    "            txt = BeautifulSoup(htmlSource, 'html.parser')\n",
    "            browser.close()\n",
    "            job_desc.append(txt.find('div','jobsearch-jobDescriptionText'))  #Append the full description of the job to our list\n",
    "            job_desc.append('#---------------------------------------------------------------------------------------------------#')\n",
    "            print(details_url)\n",
    "            job_desc.append('#---------------------------------------------------------------------------------------------------#')\n",
    "\n",
    "        # print(job_desc) \n",
    "        \n",
    "        try:\n",
    "            url = 'https://www.indeed.com' + soup.find('a',{'aria-label': 'Next'}).get('href')\n",
    "        except AttributeError:\n",
    "            break\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "violent-tragedy",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Getting all the jobs cards to find their IDs for full desc.\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "cards = soup.find_all('div', 'jobsearch-SerpJobCard') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "public-diary",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.indeed.com/jobs?q=software&l=california&fromage=7&advn=9257281766953058&vjk=37b7a6027ef55921\n",
      "https://www.indeed.com/jobs?q=software&l=california&fromage=7&advn=3399501605239740&vjk=3a31b3bd15307f87\n",
      "https://www.indeed.com/jobs?q=software&l=california&fromage=7&advn=None&vjk=b306a1ebf5c47a9e\n",
      "https://www.indeed.com/jobs?q=software&l=california&fromage=7&advn=2556084698700334&vjk=7e4807b89c872ba9\n",
      "https://www.indeed.com/jobs?q=software&l=california&fromage=7&advn=2556084698700334&vjk=f76dbac531b6b991\n",
      "https://www.indeed.com/jobs?q=software&l=california&fromage=7&advn=5809567387809865&vjk=89b44a68eedc84f4\n",
      "https://www.indeed.com/jobs?q=software&l=california&fromage=7&advn=None&vjk=efcf48300d1bad2d\n",
      "https://www.indeed.com/jobs?q=software&l=california&fromage=7&advn=None&vjk=e772e9abb572d047\n",
      "https://www.indeed.com/jobs?q=software&l=california&fromage=7&advn=8690912762161442&vjk=98e292d6494e9569\n",
      "https://www.indeed.com/jobs?q=software&l=california&fromage=7&advn=None&vjk=7290dfd840b35c5a\n",
      "https://www.indeed.com/jobs?q=software&l=california&fromage=7&advn=8690912762161442&vjk=6313df3a4a0526dd\n",
      "https://www.indeed.com/jobs?q=software&l=california&fromage=7&advn=None&vjk=5d11843eebc355f6\n",
      "https://www.indeed.com/jobs?q=software&l=california&fromage=7&advn=8690912762161442&vjk=e36528568c007b02\n",
      "https://www.indeed.com/jobs?q=software&l=california&fromage=7&advn=3325178319375701&vjk=2abd34a4bf110dfc\n",
      "https://www.indeed.com/jobs?q=software&l=california&fromage=7&advn=None&vjk=1bd7429a24e29245\n"
     ]
    }
   ],
   "source": [
    "##### Loop thru all the jobs and gather descriptions\n",
    "\n",
    "job_desc = [] #list containing all descriptions\n",
    "length = len(cards)\n",
    "for x in range(length):\n",
    "    advn = cards[x].get('data-empn')\n",
    "    vjk = cards[x].get('data-jk')\n",
    "    details_url = get_details_url(url,advn,vjk) #append and generate new Url\n",
    "\n",
    "    #Open and load page using webdriver so we can get parse elements that load after our initial request\n",
    "    \n",
    "    browser = webdriver.Chrome(r'C:\\Program Files (x86)\\Google\\Chrome\\Application\\chromedriver.exe')  \n",
    "    browser.get(details_url)\n",
    "    htmlSource = browser.page_source\n",
    "    txt = BeautifulSoup(htmlSource, 'html.parser')\n",
    "    browser.close()\n",
    "    job_desc.append(txt.find('div','jobsearch-jobDescriptionText'))  #Append the full description of the job to our list\n",
    "    job_desc.append('#---------------------------------------------------------------------------------------------------#')\n",
    "    print(details_url)\n",
    "    job_desc.append('#---------------------------------------------------------------------------------------------------#')\n",
    "        \n",
    "# print(job_desc) \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "canadian-packet",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import nltk\n",
    "# from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "# from nltk.corpus import PlaintextCorpusReader\n",
    "# string1 = ''.join(map(str,job_desc))\n",
    "# cleanText = nltk.Text(nltk.word_tokenize(string1))\n",
    "# # corp = PlaintextCorpusReader(job_desc)\n",
    "# # cleanText = nltk.Text(corp.words())\n",
    "# match = cleanText.concordance('Java')\n",
    "# match2 = cleanText.concordance('ReactJS')\n",
    "# string2 = ''.join(map(str,job_desc))\n",
    "# print(match)\n",
    "# print(match2)\n",
    "# if 'at' in listOfStrings :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "sophisticated-narrow",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Go', 'Java', 'HTML', 'ML', 'CSS', 'ReactJS', 'JS', 'AngularJS', 'JS', 'UI', 'GraphQL', 'Assembly', 'Java', 'ReactJS', 'JS', 'AngularJS', 'JS', 'UI', 'API', 'API', 'Testing', 'UI', 'UI', 'UI', 'JS', 'Angular', 'React', 'Vue', 'C#', 'Python', 'Git', 'Git', 'SQL', 'NoSQL', 'SQL', 'Linux', 'Unix', 'Azure', 'AWS', 'API', 'UI', 'Java', 'Python', 'Server', 'Testing', 'Python', 'Java', 'Java', 'SQL', 'Python', 'C#', 'SQL', 'Python', 'Cloud', 'Cloud', 'Go', 'Java', 'Git', 'Git', 'Git', 'Go', 'Go', 'Go', 'AWS', 'Azure', 'Docker', 'Docker', 'AWS', 'ML', 'AI', 'API', 'AI', 'API', 'HTML', 'ML', 'Java', 'CSS', 'Java', 'SQL', 'NoSQL', 'SQL', 'UI/UX', 'UX', 'ASP', 'ASP', 'ASP', 'UI', 'UX', 'ASP', 'C#', 'SQL', 'ASP', 'UI', 'UI', 'JS', 'Angular', 'React', 'Vue', 'C#', 'Python', 'Git', 'Git', 'SQL', 'NoSQL', 'SQL', 'Linux', 'Unix', 'Azure', 'AWS', 'API', 'Python', 'Python', 'C ', 'C++', '.Net', 'C ', 'ASP.Net ', 'C++', 'C++', 'C++', 'C ']\n"
     ]
    }
   ],
   "source": [
    "skill_lst_pattern = ['Java','C#','Python','ReactJS','VueJS','AngularJS','React','Vue','Angular','CSS','HTML',\n",
    "              'nodeJS','JS','PHP','node.js','mongoDB','MongoDB','SQL','NoSQL','ARM','Assembly','Arduino',\n",
    "              'Raspberry Pi','Pi','GraphQL','Aws','AWS','Cloud','Automation','Testing','Unit Testing',\n",
    "              'Integration Testing','CMS','Maven','Kotlin','Headless','iOS','IOS','Android','Flutter','Linux','Server',\n",
    "              'Data Processing','Data Cleaning','Data Mining','Data Science','Docker','PostgreSQL','Typescript','Restful',\n",
    "              'API','Ruby','Ruby on Rails','ES6','ES5','Json','Android Studio','React Native','Azure','UI/UX','UI','UX',\n",
    "              'Gatsby','Go','Golang','Dart','Javascript','JavaScript','Cuda','Unix','Gpu','GPU','Big Data','ASP',\n",
    "              'Asp.net','Objective-C','Objective C','Animation','Graphics','Perl','Laravel','XML','Swift','Scala',\n",
    "              'Rust','Jquery','JQuery','Bootstrap','Git','Github','MVC','AI','ML','Machine Learning','Artificial Intelligence'\n",
    "              ]\n",
    "cleantxt = ''.join(map(str,job_desc))\n",
    "x = \"s C++ C/C++ and .net and .Net and node.js and Java and UI/UX and C and C++ and C/C++s and node.js and . and c capital\"\n",
    "match1 = (re.findall(r\"(?=(\"+'|'.join(skill_lst_pattern)+r\"))\", cleantxt)) # Matches our list of skills\n",
    "match2 = (re.findall(\"\\.Net|C\\/C\\+\\+|\\.net|node\\.js|Node\\.js|ASP\\.Net |C\\+\\+|C\\ \", cleantxt)) # Matches C/C++ and C and .net etc ...\n",
    "skill_lst = match1+match2 # Final result of both our regex matches\n",
    "print(skill_lst)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unavailable-mentor",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intimate-karen",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
